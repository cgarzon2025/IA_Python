{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análisis de sentimientos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias necesarias de transformers para analizar sentimientos\n",
    "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "\n",
    "# BertModel se utiliza para crear un modelo de lenguaje que puede ser utilizado para generar texto.\n",
    "# BertTokenizer se utiliza para tokenizar el texto y convertirlo en tokens.\n",
    "# AdamW es un optimizador que se utiliza para actualizar los pesos de la red neuronal.\n",
    "# get_linear_schedule_with_warmup se utiliza para ajustar el learning rate de la red neuronal.\n",
    "\n",
    "# sklearn es una librería de machine learning para Python.\n",
    "# torch es una librería de machine learning para Python.\n",
    "# numpy es una librería de machine learning para Python.\n",
    "# textwrap es una librería de machine learning para Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Inicializar unos parametros para el modelo\n",
    "RANDOM_SEED = 42        # Es una semilla aleatoria para que el modelo se comporte de la misma manera\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "DATASET_PATH = \"IMDB_Dataset.csv\"\n",
    "NCLASSES = 2\n",
    "\n",
    "# Inicializar numpy random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Inicializar torch random seed\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Incializar el dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "(10000, 2)\n",
      "Interesting and short television movie describes some of the\n",
      "machinations surrounding Jay Leno's replacing Carson as host of the\n",
      "Tonight Show. Film is currently very topical given the public drama\n",
      "surrounding Conan O'Brien and Jay Leno.<br /><br />The film does a\n",
      "good job of sparking viewers' interest in the events and showing some\n",
      "of the concerns of the stakeholders, particularly of the NBC\n",
      "executives. The portrayal of Ovitz was particularly compelling and\n",
      "interesting, I thought.<br /><br />Still, many of the characters were\n",
      "only very briefly limned or touched upon, and some of the acting\n",
      "seemed perfunctory. Nevertheless, an interesting story.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "df = df[0:10000]\n",
    "\n",
    "# Imprimir el dataset\n",
    "print(df.head(1))\n",
    "\n",
    "# Imprimir el tamaño del dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Imprimir un ejemplo de review\n",
    "print('\\n'.join(wrap(df.review[200])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  One of the other reviewers has mentioned that ...      1\n",
       "1  A wonderful little production. <br /><br />The...      1\n",
       "2  I thought this was a wonderful way to spend ti...      1\n",
       "3  Basically there's a family where a little boy ...      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reajustar dataset\n",
    "df['label'] = (df['sentiment'] == 'positive').astype(int)\n",
    "df.drop('sentiment', axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777cb38310484c2b9ba856a86ff278c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\insit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\insit\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8e476e163f439eb9566ff86391be1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e6ff143d184201b3ef728e0a3c276b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ba287f0321461db028b00fd9aa6cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modelo preentrenado\n",
    "PRETRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "# Realizamos la tokenización\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like the movie, it was great!\n",
      "['i', 'really', 'like', 'the', 'movie', ',', 'it', 'was', 'great', '!']\n",
      "[1045, 2428, 2066, 1996, 3185, 1010, 2009, 2001, 2307, 999]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de tokenización\n",
    "sample_txt = 'I really like the movie, it was great!'\n",
    "print(sample_txt)\n",
    "\n",
    "# Tokenizar el texto\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "print(tokens)\n",
    "\n",
    "# Convertir tokens a ids\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2428, 2066, 1996, 3185, 1010, 2009, 2001,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\insit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Condificacion para introducir a BERT\n",
    "encoding = tokenizer.encode_plus(\n",
    "    sample_txt,\n",
    "    max_length=10,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "\n",
    "print(encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'really', 'like', 'the', 'movie', ',', 'it', 'was', '[SEP]']\n",
      "tensor([ 101, 1045, 2428, 2066, 1996, 3185, 1010, 2009, 2001,  102])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convertir encoding a ids\n",
    "encoding.keys()\n",
    "\n",
    "# Obtener los \n",
    "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'][0]))\n",
    "print(encoding['input_ids'][0])\n",
    "print(encoding['attention_mask'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el dataset\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    # Obtener el tamaño del dataset\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    # Obtener un item del dataset\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        # Tokenizar el texto\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducir los datos al dataset\n",
    "\n",
    "def data_loader(df, tokenizer, max_len, batch_size):\n",
    "    dataset = IMDBDataset(\n",
    "        reviews=df['review'].to_numpy(),\n",
    "        labels=df['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en train y test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Crear los dataloaders\n",
    "train_loader = data_loader(train_df, tokenizer, MAX_LEN, TRAIN_BATCH_SIZE)\n",
    "test_loader = data_loader(test_df, tokenizer, MAX_LEN, TRAIN_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, cls_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        drop_output = self.drop(cls_output)\n",
    "        linear_output = self.linear(drop_output)\n",
    "        return linear_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5175e9d1544deb884c4ac9aa3e6c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = SentimentClassifier(n_classes=NCLASSES)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "# Definir el número de épocas\n",
    "N_EPOCHS = 3\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * N_EPOCHS\n",
    "\n",
    "# Crear el scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Definir la función de pérdida\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la función de entrenamiento\n",
    "def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # Se recorre el dataloader y se obtiene el input_ids, attention_mask y labels\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Se obtiene el output del modelo\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Se obtiene el predicho por el modelo\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        # Se convierte el predicho a numpy\n",
    "        preds = preds.cpu().numpy()\n",
    "        \n",
    "        # Se convierte el labels a numpy\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        correct_predictions += np.sum(preds == labels)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Se actualiza el modelo\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de evaluación\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # Se recorre el dataloader y se obtiene el input_ids, attention_mask y labels\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            correct_predictions += np.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1} / {N_EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    train_acc, train_loss = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_df)\n",
    "    )\n",
    "    test_acc, test_loss = eval_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(test_df)\n",
    "    )\n",
    "    print(f'Entrenamiento: Train loss {train_loss} accuracy {train_acc}')\n",
    "    print(f'Evaluación: Test loss {test_loss} accuracy {test_acc}')\n",
    "    print('-' * 10)\n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'sentiment_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para predecir\n",
    "def predict_sentiment(review_text):\n",
    "    encoding_review = tokenizer.encode_plus(\n",
    "        review_text,\n",
    "        max_length=MAX_LEN,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoding_review['input_ids'].to(device)\n",
    "    attention_mask = encoding_review['attention_mask'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    \n",
    "    print('\\n'.join(wrap(review_text)))\n",
    "    if preds:\n",
    "        print(f'Sentimiento predicho: Positivo')\n",
    "    else:\n",
    "        print(f'Sentimiento predicho: Negativo')\n",
    "\n",
    "# Predecir el sentimiento de un review\n",
    "review_text = df.review[0]\n",
    "predict_sentiment(review_text)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
