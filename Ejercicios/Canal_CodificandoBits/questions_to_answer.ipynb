{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT -> **Pregustas y respuestas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\insit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerias necesarias de transformers\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "# AutoTokenizer es el tokenizador que se va a utilizar para el modelo\n",
    "# AutoModelForQuestionAnswering es el modelo que se va a utilizar para la pregunta y respuesta\n",
    "# pipeline es el pipeline que se va a utilizar para la pregunta y respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo y el tokenizador\n",
    "the_model = 'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n",
    "tokenizer = AutoTokenizer.from_pretrained(the_model, do_lower_case=False)\n",
    "\n",
    "# Cargamos el modelo\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(the_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]             4\n",
      "\n",
      "¿              1067\n",
      "\n",
      "Cuál           4542\n",
      "\n",
      "es             1058\n",
      "\n",
      "la             1030\n",
      "\n",
      "capital        3611\n",
      "\n",
      "de             1008\n",
      "\n",
      "Colombia       6634\n",
      "\n",
      "?              1064\n",
      "\n",
      "[SEP]             5\n",
      "\n",
      "La             1198\n",
      "\n",
      "capital        3611\n",
      "\n",
      "de             1008\n",
      "\n",
      "Colombia       6634\n",
      "\n",
      "es             1058\n",
      "\n",
      "Bogotá        17521\n",
      "\n",
      "y              1042\n",
      "\n",
      "está           1266\n",
      "\n",
      "situada        7757\n",
      "\n",
      "en             1036\n",
      "\n",
      "el             1040\n",
      "\n",
      "centro         3040\n",
      "\n",
      "del            1072\n",
      "\n",
      "país           1560\n",
      "\n",
      ".              1009\n",
      "\n",
      "[SEP]             5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de pregunta y respuesta\n",
    "question = \"¿Cuál es la capital de Colombia?\"\n",
    "context = \"La capital de Colombia es Bogotá y está situada en el centro del país.\"\n",
    "\n",
    "# Codificamos la pregunta y respuesta (contexto)\n",
    "encode = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "\n",
    "# Se saca los inputs_ids\n",
    "input_ids = encode['input_ids'].tolist()\n",
    "\n",
    "# Sacamos los tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "# redorremos los tokens\n",
    "for id, token in zip(input_ids[0], tokens):\n",
    "    print('{:<12} {:>6}'.format(token, id))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9815140962600708, 'start': 26, 'end': 32, 'answer': 'Bogotá'}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de inferencia (pregunta y respuesta)\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Se obtiene la salida del modelo\n",
    "output = nlp(question=question, context=context)\n",
    "\n",
    "# Se imprime la salida\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
